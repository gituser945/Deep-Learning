{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "buried-belle",
   "metadata": {},
   "source": [
    "### LENET Implementation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "animated-fever",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Packages\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D,Dense,Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "aware-matrix",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating model\n",
    "\n",
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "statutory-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding convolutional layer\n",
    "\n",
    "model.add(Conv2D(6,kernel_size = (3,3),input_shape = (32,32,3),activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "hearing-mount",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding pooling layer\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "equivalent-flexibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding convolution layer\n",
    "\n",
    "model.add(Conv2D(16,kernel_size = (3,3),activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "exact-copyright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding pooling layer\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "naughty-conditioning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding flatten layer\n",
    "\n",
    "model.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "royal-binary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding Dense Layer\n",
    "\n",
    "model.add(Dense(120,activation = 'relu'))\n",
    "model.add(Dense(84,activation = 'relu'))\n",
    "model.add(Dense(3,activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "extreme-clinic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compling the model\n",
    "\n",
    "model.compile(loss = keras.metrics.categorical_crossentropy,optimizer = keras.optimizers.Adam(),metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "tribal-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating train and test data\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "test_data = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "complimentary-attribute",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30 images belonging to 3 classes.\n",
      "Found 3 images belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "# creating training and test data\n",
    "\n",
    "train_set = train_data.flow_from_directory('/Users/nick/Desktop/DataScience/DeepLearning/CNN3/data/',\n",
    "                                           target_size = (32,32),batch_size = 16,class_mode = 'categorical')\n",
    "test_set = train_data.flow_from_directory('/Users/nick/Desktop/DataScience/DeepLearning/CNN3/images/Test/image/',\n",
    "                                           target_size = (32,32),batch_size = 16,class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "tropical-badge",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "2/2 [==============================] - 2s 754ms/step - loss: 1.1017 - accuracy: 0.3903 - val_loss: 1.0829 - val_accuracy: 0.6667\n",
      "Epoch 2/20\n",
      "2/2 [==============================] - 1s 408ms/step - loss: 1.0926 - accuracy: 0.4125 - val_loss: 1.0572 - val_accuracy: 1.0000\n",
      "Epoch 3/20\n",
      "2/2 [==============================] - 1s 407ms/step - loss: 1.0688 - accuracy: 0.5444 - val_loss: 1.0620 - val_accuracy: 0.3333\n",
      "Epoch 4/20\n",
      "2/2 [==============================] - 1s 480ms/step - loss: 1.0456 - accuracy: 0.6111 - val_loss: 1.0437 - val_accuracy: 0.6667\n",
      "Epoch 5/20\n",
      "2/2 [==============================] - 1s 413ms/step - loss: 1.0337 - accuracy: 0.6097 - val_loss: 1.0150 - val_accuracy: 0.6667\n",
      "Epoch 6/20\n",
      "2/2 [==============================] - 1s 444ms/step - loss: 1.0134 - accuracy: 0.7302 - val_loss: 1.0067 - val_accuracy: 0.6667\n",
      "Epoch 7/20\n",
      "2/2 [==============================] - 1s 407ms/step - loss: 0.9844 - accuracy: 0.6306 - val_loss: 1.0146 - val_accuracy: 0.6667\n",
      "Epoch 8/20\n",
      "2/2 [==============================] - 1s 397ms/step - loss: 0.9523 - accuracy: 0.6306 - val_loss: 0.9600 - val_accuracy: 0.6667\n",
      "Epoch 9/20\n",
      "2/2 [==============================] - 1s 458ms/step - loss: 0.9262 - accuracy: 0.6958 - val_loss: 0.9084 - val_accuracy: 0.6667\n",
      "Epoch 10/20\n",
      "2/2 [==============================] - 1s 481ms/step - loss: 0.8907 - accuracy: 0.8222 - val_loss: 0.9230 - val_accuracy: 0.6667\n",
      "Epoch 11/20\n",
      "2/2 [==============================] - 1s 438ms/step - loss: 0.8697 - accuracy: 0.7286 - val_loss: 0.8555 - val_accuracy: 0.6667\n",
      "Epoch 12/20\n",
      "2/2 [==============================] - 1s 430ms/step - loss: 0.8413 - accuracy: 0.8028 - val_loss: 0.8715 - val_accuracy: 0.6667\n",
      "Epoch 13/20\n",
      "2/2 [==============================] - 1s 390ms/step - loss: 0.8048 - accuracy: 0.7389 - val_loss: 0.7087 - val_accuracy: 1.0000\n",
      "Epoch 14/20\n",
      "2/2 [==============================] - 1s 482ms/step - loss: 0.7251 - accuracy: 0.8413 - val_loss: 0.8118 - val_accuracy: 1.0000\n",
      "Epoch 15/20\n",
      "2/2 [==============================] - 1s 400ms/step - loss: 0.6586 - accuracy: 0.8694 - val_loss: 0.7638 - val_accuracy: 0.6667\n",
      "Epoch 16/20\n",
      "2/2 [==============================] - 1s 419ms/step - loss: 0.6829 - accuracy: 0.8042 - val_loss: 0.6550 - val_accuracy: 0.6667\n",
      "Epoch 17/20\n",
      "2/2 [==============================] - 1s 476ms/step - loss: 0.5868 - accuracy: 0.7730 - val_loss: 0.6135 - val_accuracy: 0.6667\n",
      "Epoch 18/20\n",
      "2/2 [==============================] - 1s 506ms/step - loss: 0.6135 - accuracy: 0.8264 - val_loss: 0.5967 - val_accuracy: 0.6667\n",
      "Epoch 19/20\n",
      "2/2 [==============================] - 1s 459ms/step - loss: 0.4573 - accuracy: 0.9556 - val_loss: 0.3701 - val_accuracy: 1.0000\n",
      "Epoch 20/20\n",
      "2/2 [==============================] - 1s 440ms/step - loss: 0.4591 - accuracy: 0.9556 - val_loss: 0.3544 - val_accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fb22f2cf490>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model\n",
    "\n",
    "model.fit(train_set,\n",
    "                  steps_per_epoch = len(train_set),\n",
    "                  epochs = 20,\n",
    "                  validation_data = test_set,\n",
    "                  validation_steps = len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "earned-tumor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.0000000e+00 0.0000000e+00 1.4084236e-17]]\n",
      "Aamir\n"
     ]
    }
   ],
   "source": [
    "# predicting result\n",
    "\n",
    "test_image = image.load_img('/Users/nick/Downloads/IMG_7129.JPG', \n",
    "                            target_size = (32, 32))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = model.predict(test_image)\n",
    "train_set.class_indices\n",
    "print(result)\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'Aamir'\n",
    "    print(prediction)\n",
    "elif result[0][1] == 1:\n",
    "    prediction = 'Aaruti'\n",
    "    print(prediction)\n",
    "elif result[0][2]== 1:\n",
    "    prediction = 'Anand'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'Unknown Person'\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
