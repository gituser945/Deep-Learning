{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "continent-darwin",
   "metadata": {},
   "source": [
    "### Convolution Neural Network\n",
    "> Image Recognition "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ultimate-municipality",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing keras packages\n",
    "\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPool2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.preprocessing import image\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "traditional-kelly",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing the CNN\n",
    "\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "therapeutic-ethnic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating convolution layer 1\n",
    "\n",
    "classifier.add(Conv2D(32,(3,3),input_shape = (64,64,3),activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "european-damage",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating pooling layer 2\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "applicable-expression",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating convulation layer 3\n",
    "\n",
    "classifier.add(Conv2D(32,(3,3),activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "meaningful-reproduction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating. pooling layer 4\n",
    "\n",
    "classifier.add(MaxPool2D(pool_size = (2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "corresponding-request",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Flatten to convert matrix into array\n",
    "\n",
    "classifier.add(Flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "immune-republic",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now creating feed froward network using Dense function\n",
    "# units = 128 is basically 128 neurons\n",
    "\n",
    "classifier.add(Dense(units = 128,activation = 'relu'))\n",
    "classifier.add(Dense(units = 1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "welsh-drawing",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling CNN model\n",
    "\n",
    "classifier.compile(optimizer = 'adam',loss = 'binary_crossentropy',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "welsh-hygiene",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting CNN to image\n",
    "\n",
    "train_data = ImageDataGenerator(rescale = 1./255,shear_range = 0.2,zoom_range = 0.2,horizontal_flip = True)\n",
    "test_data = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "incomplete-radical",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 277 images belonging to 2 classes.\n",
      "Found 277 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_data.flow_from_directory('/Users/nick/Desktop/Deep Learning/CNN/PetImages',target_size = (64,64),batch_size = 32,class_mode = 'binary')\n",
    "\n",
    "test_set = test_data.flow_from_directory('/Users/nick/Desktop/Deep Learning/CNN/PetImages',target_size = (64,64),batch_size = 32,class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dirty-chance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "9/9 [==============================] - 2s 261ms/step - loss: 0.3978 - accuracy: 0.8051 - val_loss: 0.4186 - val_accuracy: 0.7708\n",
      "Epoch 2/20\n",
      "9/9 [==============================] - 2s 244ms/step - loss: 0.3879 - accuracy: 0.8412 - val_loss: 0.3981 - val_accuracy: 0.7708\n",
      "Epoch 3/20\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.3808 - accuracy: 0.8412 - val_loss: 0.3431 - val_accuracy: 0.8438\n",
      "Epoch 4/20\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 0.3385 - accuracy: 0.8736 - val_loss: 0.3263 - val_accuracy: 0.8229\n",
      "Epoch 5/20\n",
      "9/9 [==============================] - 2s 264ms/step - loss: 0.3478 - accuracy: 0.8520 - val_loss: 0.2803 - val_accuracy: 0.8854\n",
      "Epoch 6/20\n",
      "9/9 [==============================] - 3s 265ms/step - loss: 0.3320 - accuracy: 0.8736 - val_loss: 0.2971 - val_accuracy: 0.8438\n",
      "Epoch 7/20\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.3069 - accuracy: 0.8989 - val_loss: 0.3012 - val_accuracy: 0.8854\n",
      "Epoch 8/20\n",
      "9/9 [==============================] - 2s 256ms/step - loss: 0.3558 - accuracy: 0.8520 - val_loss: 0.3462 - val_accuracy: 0.8021\n",
      "Epoch 9/20\n",
      "9/9 [==============================] - 2s 259ms/step - loss: 0.2804 - accuracy: 0.8953 - val_loss: 0.2015 - val_accuracy: 0.9062\n",
      "Epoch 10/20\n",
      "9/9 [==============================] - 2s 252ms/step - loss: 0.2792 - accuracy: 0.8953 - val_loss: 0.2202 - val_accuracy: 0.9271\n",
      "Epoch 11/20\n",
      "9/9 [==============================] - 2s 271ms/step - loss: 0.2879 - accuracy: 0.8989 - val_loss: 0.2088 - val_accuracy: 0.9479\n",
      "Epoch 12/20\n",
      "9/9 [==============================] - 2s 249ms/step - loss: 0.2573 - accuracy: 0.9170 - val_loss: 0.2225 - val_accuracy: 0.9062\n",
      "Epoch 13/20\n",
      "9/9 [==============================] - 2s 259ms/step - loss: 0.2500 - accuracy: 0.8953 - val_loss: 0.1372 - val_accuracy: 0.9583\n",
      "Epoch 14/20\n",
      "9/9 [==============================] - 2s 254ms/step - loss: 0.2174 - accuracy: 0.9134 - val_loss: 0.1403 - val_accuracy: 0.9479\n",
      "Epoch 15/20\n",
      "9/9 [==============================] - 2s 250ms/step - loss: 0.2343 - accuracy: 0.9134 - val_loss: 0.1174 - val_accuracy: 0.9792\n",
      "Epoch 16/20\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 0.1632 - accuracy: 0.9386 - val_loss: 0.1539 - val_accuracy: 0.9479\n",
      "Epoch 17/20\n",
      "9/9 [==============================] - 3s 287ms/step - loss: 0.1745 - accuracy: 0.9206 - val_loss: 0.1288 - val_accuracy: 0.9375\n",
      "Epoch 18/20\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 0.1961 - accuracy: 0.9170 - val_loss: 0.1848 - val_accuracy: 0.9375\n",
      "Epoch 19/20\n",
      "9/9 [==============================] - 2s 256ms/step - loss: 0.2175 - accuracy: 0.9170 - val_loss: 0.1423 - val_accuracy: 0.9479\n",
      "Epoch 20/20\n",
      "9/9 [==============================] - 2s 253ms/step - loss: 0.2073 - accuracy: 0.9170 - val_loss: 0.1219 - val_accuracy: 0.9271\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f9eb3cd11c0>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting model\n",
    "\n",
    "classifier.fit_generator(train_set,\n",
    "                         steps_per_epoch = 9,\n",
    "                         epochs = 20,\n",
    "                         validation_data = test_set,\n",
    "                         validation_steps = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "agricultural-advertiser",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cat\n"
     ]
    }
   ],
   "source": [
    "# Predicting\n",
    "\n",
    "test_image = image.load_img('/Users/nick/Desktop/Deep Learning/CNN/Test/image2.jpg', target_size = (64, 64))\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "result = classifier.predict(test_image)\n",
    "train_set.class_indices\n",
    "if result[0][0] == 1:\n",
    "    prediction = 'dog'\n",
    "    print(prediction)\n",
    "else:\n",
    "    prediction = 'cat'\n",
    "    print(prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
