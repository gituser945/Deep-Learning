{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "stuffed-asthma",
   "metadata": {},
   "source": [
    "#### IMDB Classification using RNN LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "considerable-owner",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Embedding,LSTM\n",
    "from keras.datasets import imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "compound-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting parameters for dataset\n",
    "\n",
    "max_features = 20000\n",
    "maxlen = 80\n",
    "batch_size = 36"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "chronic-section",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
      "17465344/17464789 [==============================] - 364s 21us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "/Users/nick/opt/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "/Users/nick/opt/anaconda3/envs/Tensorflow/lib/python3.8/site-packages/tensorflow/python/keras/datasets/imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    }
   ],
   "source": [
    "# train and test\n",
    "\n",
    "(X_train,y_train),(X_test,y_test) = imdb.load_data(num_words = max_features,maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "soviet-cooper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1864 train sequence\n",
      "2021 test sequence\n"
     ]
    }
   ],
   "source": [
    "# checking len of train and test\n",
    "\n",
    "print(len(X_train),'train sequence')\n",
    "print(len(X_test),'test sequence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "meaningful-clause",
   "metadata": {},
   "outputs": [],
   "source": [
    "# padding operation\n",
    "\n",
    "X_train = sequence.pad_sequences(X_train,maxlen = maxlen)\n",
    "X_test = sequence.pad_sequences(X_test,maxlen = maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "personalized-earthquake",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model buiding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_features,128))\n",
    "model.add(LSTM(128,dropout = 0.2,recurrent_dropout = 0.2))\n",
    "model.add(Dense(1,activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "respected-bosnia",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model compilation\n",
    "\n",
    "model.compile(loss = 'binary_crossentropy',optimizer = 'adam',metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "comprehensive-premium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "52/52 [==============================] - 14s 264ms/step - loss: 0.3103 - accuracy: 0.8755 - val_loss: 0.4268 - val_accuracy: 0.8263\n",
      "Epoch 2/5\n",
      "52/52 [==============================] - 14s 267ms/step - loss: 0.1217 - accuracy: 0.9576 - val_loss: 0.4362 - val_accuracy: 0.8105\n",
      "Epoch 3/5\n",
      "52/52 [==============================] - 13s 256ms/step - loss: 0.0655 - accuracy: 0.9855 - val_loss: 0.4979 - val_accuracy: 0.8258\n",
      "Epoch 4/5\n",
      "52/52 [==============================] - 14s 266ms/step - loss: 0.0421 - accuracy: 0.9893 - val_loss: 0.6634 - val_accuracy: 0.8125\n",
      "Epoch 5/5\n",
      "52/52 [==============================] - 13s 255ms/step - loss: 0.0095 - accuracy: 0.9984 - val_loss: 0.5820 - val_accuracy: 0.8234\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f8dd8b9bc10>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model fitting\n",
    "\n",
    "model.fit(X_train,y_train,epochs = 5,batch_size = batch_size,validation_data = (X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aware-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80261445],\n",
       "       [0.9931395 ],\n",
       "       [0.97000074],\n",
       "       ...,\n",
       "       [0.00703862],\n",
       "       [0.99945885],\n",
       "       [0.24354023]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prediction\n",
    "\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "danish-point",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57/57 [==============================] - 2s 29ms/step - loss: 0.5820 - accuracy: 0.8234\n"
     ]
    }
   ],
   "source": [
    "# accuracy\n",
    "\n",
    "acc = model.evaluate(X_test,y_test,batch_size = batch_size)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
